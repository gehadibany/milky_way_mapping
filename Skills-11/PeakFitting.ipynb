{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting models to data - peak fitting\n",
    "\n",
    "Version 0.2 Dec 2019\n",
    "\n",
    "This notebook follows on from the LineFitting exercises.  \n",
    "\n",
    "You should complete the LineFitting notebook before working through this one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SciPy `curve_fit()` and `odr()` functions that we used in the LineFitting notebook allow you to define pretty much any model you want to fit your data.\n",
    "\n",
    "As an example, a Gaussian curve can be defined using three parameters:\n",
    "\n",
    "$$A \\exp{\\left(\\frac{-(x - x_0)^2}{(2 \\sigma^2)}\\right)}$$\n",
    "\n",
    "Where $A$ is its amplitude, $x_0$ its position on the $x$ axis, and $\\sigma$ a measure of its width.\n",
    "\n",
    "A Gaussian curve of this form can be used to model and to fit peaks in spectra - you will encounter these in the Compton experiment in the Physics project, and later in the infrared spectroscopy experiment in the Mars project.\n",
    "\n",
    "In this notebook, we'll explore how to use the tools available in SciPy to fit a Gaussian model to a sample dataset.  The process involves optimising the parameters in a model function to minimise the sum of squares, in a similar way to the straight line fitting.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0 Imports and housekeeping\n",
    "\n",
    "Before inspecting the data and fitting the model, we'll start by importing the necessary packages - these include the familiar packages NumPy, Pandas and Matplotlib.  In this notebook we will also make use of Bokeh for some of the plotting, simply to gain more experience of using Bokeh (Matplotlib would work here just as well). \n",
    "\n",
    "In later cells we will also make use of SciPy for the peak fitting. \n",
    "\n",
    "Results are persistent from one cell to another, so remember to run cells in sequence.  Most importantly, we need to import packages before using them.  The next cell does this, as well as setting up some other items that we will use later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from bokeh.plotting import figure, output_notebook, show\n",
    "\n",
    "# These two lines enable formatted printing of Pandas DataFrames\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Data inspection\n",
    "\n",
    "For the exercises in this notebook, a file with sample data is provided. `PeakData.csv` is a csv file that can be read in using Pandas in the usual way. \n",
    "\n",
    "This file represents the type of data that might typically come from a thermally broadened spectral line. The physics of this indicate that a Gaussian should be a good model to use.\n",
    "\n",
    "The sample dataset was generated using the following values:  $A = 20$, $x_0 = 10$, $\\sigma  = 1.0$ with a random $y$ noise value added. \n",
    "\n",
    "As in previous examples, the first task is data inspection, so we will start by reading in the file, inspecting the contents of the resulting DataFrame and making a plot of the raw data.\n",
    "\n",
    "This time, instead of passing the columns to `Matplotlib.pyplot`, we can use the `pandas.DataFrame.plot()` function.  This creates a Matplotlib plot based on the columns in the data frame, and is an example of Pandas and Matplotlib working together.\n",
    "\n",
    "https://pandas.pydata.org/pandas-docs/version/0.23.4/generated/pandas.DataFrame.plot.html\n",
    "\n",
    "Later examples in this notebook will be plotted using Bokeh, to illustrate the different options available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PeakData = pd.read_csv('PeakData.csv')\n",
    "\n",
    "# Display first few lines of the dataset\n",
    "PeakData.head()\n",
    "\n",
    "#Set the size of subsequent Matplotlib plots\n",
    "plt.rcParams['figure.figsize'] = [12, 7.5]\n",
    "\n",
    "# This illustrates a different way of plotting the data\n",
    "# Pandas and Matplotlib work together - this time \n",
    "# we use the Pandas DataFrame function plot(), which creates\n",
    "# a Matplotlib plot\n",
    "PeakData.plot('x', 'y', kind = 'scatter', title = 'Sample peak data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Peak fitting\n",
    "\n",
    "Fitting a Gaussian model to the peak in the dataset follows a similar process to the line fitting using `scipy.optimize.curvefit()`.  The first step is to define a _model function_.   In this case, the model is a Gaussian curve.  \n",
    "\n",
    "As with the straight line fit, the model involves a number of parameters (for the Gaussian curve these are $A$, $x_0$ and $\\sigma$). The model function will be called repeatedly by `curve_fit()` as it optimises the values of these three parameters.\n",
    "\n",
    "This time, a list of initial values for these three parameters (p0) is provided as an extra input to the `curve_fit()` function. \n",
    "\n",
    "These initial approximate parameters are used by the `curve_fit()` function to use as a starting point for the optimised values. This is optional but can be useful if the dataset is complex or noisy as it can improve the quality and speed of the fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Import the necessary SciPy functions\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "# Tell Bokeh to display plots in the notebook\n",
    "output_notebook()\n",
    "\n",
    "# define a Gaussian model\n",
    "def GaussModel(x, a, x0, sigma):\n",
    "    y_gauss = a*np.exp(-(x-x0)**2/(2*sigma**2))\n",
    "    return y_gauss\n",
    "\n",
    "# Define variables to refer to the x and y data columns\n",
    "#  - not strictly necessary, but convenient\n",
    "x  = PeakData['x']\n",
    "y  = PeakData['y']\n",
    "\n",
    "# Do the fit - p0 defines starting points for the parameters\n",
    "p0 = [20, 10, 2]\n",
    "popt, pcov = curve_fit(GaussModel, x, y, p0)\n",
    "\n",
    "# As with the straight line fit, popt and pcov \n",
    "# contain the optimised parameters and error values\n",
    "# if you are interested, un-comment the following  lines to print\n",
    "# these out and inspect the contents\n",
    "# print(popt)\n",
    "# print(pcov)\n",
    "\n",
    "# For readability, extract values from popt into named variables\n",
    "a_fit     = popt[0]\n",
    "x0_fit    = popt[1]\n",
    "sigma_fit = popt[2]\n",
    "\n",
    "print('fit parameters')\n",
    "print('***************************************************')\n",
    "print (f'A     = {a_fit: .3g}')\n",
    "print (f'x0    = {x0_fit: .3g}')\n",
    "print (f'sigma = {sigma_fit: .3g}')\n",
    "print('***************************************************')\n",
    "\n",
    "# Calculate the errors on the returned parameters\n",
    "perr = np.sqrt(np.diag(pcov)) # squares of the error values are \n",
    "                              # on the covariance matrix diagonal\n",
    "\n",
    "# For readability, extract values from perr into named variables\n",
    "a_err     = perr[0]\n",
    "x0_err    = perr[1]\n",
    "sigma_err = perr[2]\n",
    "\n",
    "#print fit parameters and error estimates\n",
    "print()\n",
    "print('fit parameters with error estimates')\n",
    "print('***************************************************')\n",
    "print(f'A     = {a_fit: .3g} +/- {a_err: .3g}')\n",
    "print(f'x0    = {x0_fit: .3g} +/- {x0_err: .3g}')\n",
    "print(f'sigma = {sigma_fit: .3g} +/- {sigma_err: .3g}')\n",
    "print('***************************************************')\n",
    "\n",
    "# Plot the data points and the optimised curve\n",
    "# This time using Bokeh to generate an interactive plot\n",
    "p1 = figure(title = \"Fitting a Gaussian to data\", \n",
    "            x_axis_label = 'x', \n",
    "            y_axis_label = 'y')\n",
    "\n",
    "p1.scatter(x, y, legend = \"Data\")\n",
    "\n",
    "p1.line(x, GaussModel(x, a_fit, x0_fit, sigma_fit), \n",
    "        color = \"red\", \n",
    "        line_dash = \"dashed\", \n",
    "        legend = \"Optimised curve\")\n",
    "\n",
    "p1.legend.location = \"top_left\"\n",
    "p1.legend.click_policy = \"hide\"\n",
    "show(p1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Constraining the fit\n",
    "Although we have not needed it so far, `curve_fit()` allows you to set bounds for the optimised parameters. For example the physical properties of the system under investigation might mean that there will be a maximum width for any peak, or you might want to ignore Gaussians that are too small in height, and so on. \n",
    "\n",
    "The official documentation for `curve_fit()` explains how to set bounds:\n",
    "\n",
    "https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.curve_fit.html.\n",
    "\n",
    "Bounds are specified by including a `bounds = (...)` parameter in the call to `curve_fit()`.  This specifies the lower and upper limits to the values of the fitting parameters, constraining the fit to be within those bounds:\n",
    "\n",
    "`bounds = ([a_lower, x_0_lower, sigma_lower], [a_upper, x_0_upper, sigma_upper])`\n",
    "\n",
    "The bounds are set by specifying a tuple (round brackets) containing two lists (square brackets), one for the lower and one for the upper bounds.  Each list is in the same format as the list `p0`, containing values for the three fit parameters.\n",
    "\n",
    "You can try this in Exercise 2.2.  Alternatively, there is an example of setting bounds in Section 3.1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Optional exercise - setting bounds\n",
    "\n",
    "As an optional exercise, try modifying the example in the previous cell to see the effect of changing the initial values and of setting bounds on the fitted parameters.  \n",
    "\n",
    "Enter your solution in the next cell. Start by copying to program from the cell above, then modify the `curve_fit()` call by adding a `bounds = (...)` parameter.  Try varying the upper and lower values of the bounds and compare the resulting fits with the original fit above. What happens if the initial values or the constraints are too far from the values for the actual peak ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your solution here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Fitting multiple peaks\n",
    "\n",
    "So far we have looked at a dataset containing a single peak. What happens if we have more than one peak in the data ?   For instance, the data in the Compton experiment will have peaks corresponding to two different X-ray energies, together with some smaller peaks, and in the Mars project you will look at infrared spectra potentially containing multiple peaks.\n",
    " \n",
    "To explore how to handle this situation, we'll use synthesised data set, `TwinPeaks.csv` that contains two peaks. Make sure that this file is in the same folder as this notebook.\n",
    "\n",
    "We will look at three different approaches: using bounds to constrain the fit, selecting a region of interest, and building a more complex model.  Before looking at these we will set up our imports and inspect the data in the usual way (we'll import everything again so that the following examples can be run by themselves without having to run through all of the earlier cells in the notebook)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Set up imports and other housekeeping\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import curve_fit\n",
    "from bokeh.plotting import figure, output_notebook, show\n",
    "output_notebook()\n",
    "\n",
    "# These two lines enable formatted printing of Pandas DataFrames\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "TwinPeakData = pd.read_csv('TwinPeaks.csv')\n",
    "\n",
    "# Display first few lines of the dataset\n",
    "TwinPeakData.head()\n",
    "\n",
    "#Set the size of subsequent Matplotlib plots\n",
    "plt.rcParams['figure.figsize'] = [12, 7.5]\n",
    "\n",
    "# This illustrates a different way of plotting the data\n",
    "# Pandas and Matplotlib work together - this time \n",
    "# we use the Pandas DataFrame function plot(), which creates\n",
    "# a Matplotlib plot\n",
    "TwinPeakData.plot('wavelength', 'intensity', kind = 'scatter', \n",
    "                  title = 'Sample dataset with two peaks')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data inspection plot shows that there are two peaks that need fitting here - one (call it peak A) around channel 5050 and one (peak B)around channel 5085. We can also see that the first peak has a height of around 900 intensity units and a FWHM (Full Width Half Max) of around 10 wavelength units, with the second peak having a height of about 200 and a FWHM of 10.\n",
    "\n",
    "(The Full Width Half Max (FWHM) is approximately $2.35 \\sigma$ )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Use constraints\n",
    "\n",
    "The first approach involves using the initial parameters and bounds to constrain  `curve_fit()` to optimise for one peak or the other. \n",
    "\n",
    "The program in the following cell uses bounds to ensure that `curve_fit()` fits the model to Peak A.\n",
    "\n",
    "Refer to Section 2.1 for more details on setting bounds.\n",
    "\n",
    "In the following program, the bounds are specified by setting up lists for the lower and upper bounds.  These are then included in the `bounds = (...)` parameter within the call to `curve_fit`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a Gaussian model\n",
    "def GaussModel(x, a, x0, sigma):\n",
    "    y_gauss = a*np.exp(-(x-x0)**2/(2*sigma**2))\n",
    "    return y_gauss\n",
    "\n",
    "TwinPeakData = pd.read_csv('TwinPeaks.csv')\n",
    "\n",
    "# Define variables to refer to the x and y data columns\n",
    "#  - not strictly necessary, but convenient\n",
    "x  = TwinPeakData['wavelength']\n",
    "y  = TwinPeakData['intensity']\n",
    "\n",
    "# Specify starting parameters that approximately match Peak A\n",
    "p0 = [900, 5050, 4]\n",
    "# Specify lower and upper bounds. Each is a list of the three values\n",
    "p_lower = [500, 5040, 1]\n",
    "p_upper = [1200, 5060, 10]\n",
    "\n",
    "# The bounds constrain fit to region of Peak A\n",
    "# The bounds are specified as a tuple with two elements.  \n",
    "# The first is a list of the lower bounds of the \n",
    "# three parameters, and the second a list of the upper bounds\n",
    "popt, pcov = curve_fit(GaussModel, x, y, p0, bounds = (p_lower, p_upper))\n",
    "\n",
    "# TODO: Change the initial values and bounds to match Peak B\n",
    "#\n",
    "# TODO: Modify the program to prompt the user to specify values\n",
    "\n",
    "# For readability, extract values from popt into named variables\n",
    "a_fit     = popt[0]\n",
    "x0_fit    = popt[1]\n",
    "sigma_fit = popt[2]\n",
    "\n",
    "print('fit parameters')\n",
    "print('***************************************************')\n",
    "print (f'A     = {a_fit: .3g}')\n",
    "print (f'x0    = {x0_fit: .3g}')\n",
    "print (f'sigma = {sigma_fit: .3g}')\n",
    "print('***************************************************')\n",
    "\n",
    "# Calculate the errors on the returned parameters\n",
    "perr = np.sqrt(np.diag(pcov)) # squares of the error values are \n",
    "                              # on the covariance matrix diagonal\n",
    "\n",
    "# For readability, extract values from perr into named variables\n",
    "a_err     = perr[0]\n",
    "x0_err    = perr[1]\n",
    "sigma_err = perr[2]\n",
    "\n",
    "#print fit parameters and error estimates\n",
    "print()\n",
    "print('fit parameters with error estimates')\n",
    "print('***************************************************')\n",
    "print(f'A     = {a_fit: .3g} +/- {a_err: .3g}')\n",
    "print(f'x0    = {x0_fit: .3g} +/- {x0_err: .3g}')\n",
    "print(f'sigma = {sigma_fit: .3g} +/- {sigma_err: .3g}')\n",
    "print('***************************************************')\n",
    "\n",
    "# Plot the data points and the optimised curve\n",
    "# This time using Bokeh to generate an interactive plot\n",
    "p1 = figure(title = \"Fitting a Gaussian to data\", \n",
    "            x_axis_label = \"Wavelength (Angstroms)\", \n",
    "            y_axis_label = \"Intensity\")\n",
    "\n",
    "p1.scatter(x,y, legend = \"Data\")\n",
    "\n",
    "p1.line(x, GaussModel(x, a_fit, x0_fit, sigma_fit), \n",
    "        color = \"red\", \n",
    "        line_dash = \"dashed\", \n",
    "        legend = \"Optimised curve\")\n",
    "# Mark centreline\n",
    "p1.line((x0_fit, x0_fit),(0, a_fit*1.10),\n",
    "        color = \"blue\", \n",
    "        line_dash = \"dotted\", \n",
    "        legend = \"Centreline\")\n",
    "\n",
    "p1.legend.location = \"top_left\"\n",
    "p1.legend.click_policy = \"hide\"\n",
    "show(p1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Exercise - use constraints to fit to Peak B\n",
    "\n",
    "Copy the program from 3.1 and modify the initial values and bounds to constrain `curve_fit()` to fitting Peak B.\n",
    "\n",
    "You may also wish to modify the program so that it prompts the user to specify values for the constraints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your solution here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Isolate the specific area of interest.\n",
    "\n",
    "An alternative approach would be to isolate the area of interest by passing a limited range of the data to `curve_fit()`.  To do this, we'll create a subset of the full spectrum containing just the values in the region of the peak we are interested in.  This can be done using the Pandas `loc` function to specify a slice of the dataset.\n",
    "\n",
    "This time, we will prompt the user to enter these values:\n",
    "\n",
    "1. An estimate of the $x$ position of the peak of interest.\n",
    "2. An estimate of the height.\n",
    "3. An estimate of the FWHM\n",
    "\n",
    "The FWHM value will allow us to isolate a slice of data and also give us an initial value for $\\sigma$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a Gaussian model\n",
    "def GaussModel(x, a, x0, sigma):\n",
    "    y_gauss = a*np.exp(-(x-x0)**2/(2*sigma**2))\n",
    "    return y_gauss\n",
    "\n",
    "\n",
    "TwinPeakData = pd.read_csv('TwinPeaks.csv')\n",
    "\n",
    "# Ask user to specify initial values\n",
    "a_est    = float(input('Estimated peak height: '))\n",
    "x0_est   = int(input('Estimated peak position: '))\n",
    "FWHM_est = float(input('Estimated peak FWHM: '))\n",
    "\n",
    "\n",
    "# Calculate an estimated sigma using FWHM approx = 2.35*sigma\n",
    "sigma_est = FWHM_est/2.35\n",
    "\n",
    "# We need to re-index the DataFrame on the channel data \n",
    "# This is necessary so that we can slice the data based on the displayed wavelength rather\n",
    "# than the actual data index.\n",
    "TwinPeakData.set_index('wavelength', inplace = True, drop = False)\n",
    "\n",
    "# x and y contain the full data columns\n",
    "x  = TwinPeakData['wavelength']\n",
    "y  = TwinPeakData['intensity']\n",
    "\n",
    "# Slice out region of interest\n",
    "x_range = TwinPeakData['wavelength'].loc[x0_est-FWHM_est : x0_est+FWHM_est]\n",
    "y_range = TwinPeakData['intensity'].loc[x0_est-FWHM_est : x0_est+FWHM_est]\n",
    "\n",
    "# Only data points in region of the peak are sent to curve_fit()\n",
    "popt, pcov = curve_fit(GaussModel, x_range, y_range, p0 = [a_est, x0_est, sigma_est])\n",
    "\n",
    "# For readability, extract values from popt into named variables\n",
    "a_fit     = popt[0]\n",
    "x0_fit    = popt[1]\n",
    "sigma_fit = popt[2]\n",
    "\n",
    "print('fit parameters')\n",
    "print('***************************************************')\n",
    "print(f'A     = {a_fit: .3g}')\n",
    "print(f'x0    = {x0_fit: .3g}')\n",
    "print(f'sigma = {sigma_fit: .3g}')\n",
    "print('***************************************************')\n",
    "\n",
    "# Plot the data with the optimised curve (Bokeh):\n",
    "p1 = figure(title = \"Fitting a Gaussian to multiple peaks\", \n",
    "          x_axis_label = \"Wavelength (Angstroms)\", \n",
    "          y_axis_label = \"Intensity\")\n",
    "\n",
    "# Plot entire range in light grey colour\n",
    "p1.scatter(x, y, legend = \"Data\", color = \"#D0D0D0\")\n",
    "# lot selected range in blue\n",
    "p1.scatter(x_range, y_range, legend = \"Sample\", color = \"blue\")\n",
    "\n",
    "# Plot fitted line just for the selected range\n",
    "p1.line(x_range, GaussModel(x_range, a_fit, x0_fit, sigma_fit), \n",
    "        color = \"red\", \n",
    "        line_dash = \"dashed\", \n",
    "        legend = \"Optimised curve\")\n",
    "\n",
    "# Mark centreline\n",
    "p1.line((x0_fit, x0_fit),(0, a_fit*1.10),\n",
    "        color = \"blue\", \n",
    "        line_dash = \"dotted\", \n",
    "        legend = \"Centreline\")\n",
    "\n",
    "p1.legend.location = \"top_left\"\n",
    "p1.legend.click_policy = \"hide\"\n",
    "\n",
    "show(p1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "You could now repeat for peak B - either by running the program again or by putting the whole thing in a loop.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 3.4 Create a more complex model\n",
    "\n",
    "We can also approach the problem by using more complex model that actually has two Gaussians built in.\n",
    "\n",
    "As before we could prompt the user for the initial estimates. Here, however, for brevity we'll hard-code them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a model with two Gaussians, one for each peak\n",
    "def TwinGaussModel(x, a1, x10, sigma1, a2, x20, sigma2):\n",
    "    y_gauss = a1*np.exp(-(x-x10)**2/(2*sigma1**2)) + a2*np.exp(-(x-x20)**2/(2*sigma2**2))\n",
    "    return y_gauss\n",
    "\n",
    "# Peak A\n",
    "a1_est = 900\n",
    "x10_est = 5050\n",
    "sigma1_est = 4.0\n",
    "\n",
    "# Peak B\n",
    "a2_est = 200\n",
    "x20_est = 5080\n",
    "sigma2_est = 4.0\n",
    "\n",
    "TwinPeakData = pd.read_csv('TwinPeaks.csv')\n",
    "\n",
    "# Define list of starting parameters\n",
    "p0 = [a1_est, x10_est, sigma1_est, a2_est, x20_est, sigma2_est]\n",
    "\n",
    "# x and y contain the full data columns\n",
    "x  = TwinPeakData['wavelength']\n",
    "y  = TwinPeakData['intensity']\n",
    "\n",
    "# do the fit\n",
    "popt, pcov = curve_fit(TwinGaussModel, x, y, p0)\n",
    "\n",
    "a1_fit = popt[0]\n",
    "x10_fit = popt[1]\n",
    "sigma1_fit = popt[2]\n",
    "\n",
    "a2_fit = popt[3]\n",
    "x20_fit = popt[4]\n",
    "sigma2_fit = popt[5]\n",
    "\n",
    "# Print out optimised parameters\n",
    "print('fit parameters')\n",
    "print('***************************************************')\n",
    "print('Peak A:')\n",
    "print(f'A     = {a1_fit: .3g}')\n",
    "print(f'x0    = {x10_fit: .3g}')\n",
    "print(f'sigma = {sigma1_fit: .3g}')\n",
    "print('Peak B:')\n",
    "print(f'A     = {a2_fit: .3g}')\n",
    "print(f'x0    = {x20_fit: .3g}')\n",
    "print(f'sigma = {sigma2_fit: .3g}')\n",
    "print('***************************************************')\n",
    "print(f'Peaks are at wavelengths of {x10_fit:.0f} and {x20_fit:.0f} Angstroms')\n",
    "print('***************************************************')\n",
    "\n",
    "\n",
    "# Plot the data with the optimised curve (Bokeh):\n",
    "p1 = figure(title = \"Fitting a Gaussian to multiple peaks\", \n",
    "          x_axis_label = \"Wavelength (Angstroms)\", \n",
    "          y_axis_label = \"Intensity\")\n",
    "\n",
    "p1.scatter(x, y, legend = \"Data\")\n",
    "p1.line(x, TwinGaussModel(x, a1_fit, x10_fit, sigma1_fit, \\\n",
    "                          a2_fit, x20_fit, sigma2_fit), \n",
    "        color = \"red\", \n",
    "        line_dash = \"dashed\", \n",
    "        legend = \"Optimised curve\")\n",
    "\n",
    "# Mark centrelines\n",
    "p1.line((x10_fit, x10_fit),(0, a1_fit*1.10),\n",
    "        color = \"blue\", \n",
    "        line_dash = \"dotted\", \n",
    "        legend = \"Centre Peak A\")\n",
    "\n",
    "p1.line((x20_fit, x20_fit),(0, a2_fit*1.10),\n",
    "        color = \"green\", \n",
    "        line_dash = \"dotted\", \n",
    "        legend = \"Centre Peak B\")\n",
    "\n",
    "p1.legend.location = \"top_left\"\n",
    "p1.legend.click_policy = \"hide\"\n",
    "show(p1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 3.5 Exercise: automatically detect peak\n",
    "\n",
    "As an alternative to prompting the user to specify the approximate positions, height and width of the peaks, you may wish to try detecting the peaks automatically.  This could be done, for example, by finding the maximum intensity value in the data, and where it occurs.\n",
    "\n",
    "You can do this using the Pandas functions `max()` to find the maximum value in a range of data, and `idxmax()` to find the corresponding index of that maximum value.  These would give initial values for the peak height `a_est` and position `xo_est`.\n",
    "\n",
    "To try this, modify this copy of the program from Section 3.3, replacing the user input statements with statements to find the peak height and position.  \n",
    "\n",
    "For simplicity here we have used a fixed value of 20 for FWHM_Est.  As an optional exercise, you may wish to try scanning either side of the peak value to find this automatically as well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your solution here\n",
    "# define a Gaussian model\n",
    "def GaussModel(x, a, x0, sigma):\n",
    "    y_gauss = a*np.exp(-(x-x0)**2/(2*sigma**2))\n",
    "    return y_gauss\n",
    "\n",
    "\n",
    "TwinPeakData = pd.read_csv('TwinPeaks.csv')\n",
    "\n",
    "# Instead of prompting user, set fixed value of FWHM\n",
    "FWHM_est = 20  # Fixed estimate for FWHM\n",
    "\n",
    "# Initial values of peak height and position will be found automatically\n",
    "# This must be done after re-indexing so that the position is given as\n",
    "#   an actual wavelength rather than an index number\n",
    "\n",
    "# Calculate an estimated sigma using FWHM approx = 2.35*sigma\n",
    "sigma_est = FWHM_est/2.35\n",
    "\n",
    "# We need to re-index the DataFrame on the channel data \n",
    "# This is necessary so that we can slice the data based on the displayed wavelength rather\n",
    "# than the actual data index.\n",
    "TwinPeakData.set_index('wavelength', inplace = True, drop = False)\n",
    "\n",
    "# x and y contain the full data columns\n",
    "x  = TwinPeakData['wavelength']\n",
    "y  = TwinPeakData['intensity']\n",
    "\n",
    "## TODO: use max() and idxmax() on the intensity column to find the peak height and position\n",
    "## Complete the following two lines where indicated   \n",
    "a_est = #<<<<\n",
    "x0_est = #<<<<\n",
    "\n",
    "# Slice out region of interest\n",
    "x_range = TwinPeakData['wavelength'].loc[x0_est-FWHM_est : x0_est+FWHM_est]\n",
    "y_range = TwinPeakData['intensity'].loc[x0_est-FWHM_est : x0_est+FWHM_est]\n",
    "\n",
    "# Only data points in region of the peak are sent to curve_fit()\n",
    "popt, pcov = curve_fit(GaussModel, x_range, y_range, p0 = [a_est, x0_est, sigma_est])\n",
    "\n",
    "# For readability, extract values from popt into named variables\n",
    "a_fit     = popt[0]\n",
    "x0_fit    = popt[1]\n",
    "sigma_fit = popt[2]\n",
    "\n",
    "print('fit parameters')\n",
    "print('***************************************************')\n",
    "print(f'A     = {a_fit: .3g}')\n",
    "print(f'x0    = {x0_fit: .3g}')\n",
    "print(f'sigma = {sigma_fit: .3g}')\n",
    "print('***************************************************')\n",
    "\n",
    "# Plot the data with the optimised curve (Bokeh):\n",
    "p1 = figure(title = \"Fitting a Gaussian to multiple peaks\", \n",
    "          x_axis_label = \"Wavelength (Angstroms)\", \n",
    "          y_axis_label = \"Intensity\")\n",
    "\n",
    "# Plot entire range in light grey colour\n",
    "p1.scatter(x, y, legend = \"Data\", color = \"#D0D0D0\")\n",
    "# lot selected range in blue\n",
    "p1.scatter(x_range, y_range, legend = \"Sample\", color = \"blue\")\n",
    "\n",
    "# Plot fitted line just for the selected range\n",
    "p1.line(x_range, GaussModel(x_range, a_fit, x0_fit, sigma_fit), \n",
    "        color = \"red\", \n",
    "        line_dash = \"dashed\", \n",
    "        legend = \"Optimised curve\")\n",
    "\n",
    "# Mark centreline\n",
    "p1.line((x0_fit, x0_fit),(0, a_fit*1.10),\n",
    "        color = \"blue\", \n",
    "        line_dash = \"dotted\", \n",
    "        legend = \"Centreline\")\n",
    "\n",
    "p1.legend.location = \"top_left\"\n",
    "p1.legend.click_policy = \"hide\"\n",
    "\n",
    "show(p1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 3.6 Optional exercise: automatically detect both peaks\n",
    "\n",
    "The example in 3.5 works to find the largest peak in the scan.\n",
    "\n",
    "As a further optional exercise, try modifying the program from 3.4 in a similar way to find both peak A and peak B.\n",
    "\n",
    "Copy the program from 3.4 into the cell below and modify as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 4 Conclusions and taking it further\n",
    "\n",
    "In this notebook, we have seen how to use `scipy.optimise.curve_fit()` to fit increasingly complex curves to a set of data, and specifically to fit a model involving Gaussian peaks to peaks in a simulated spectrum.\n",
    "\n",
    "We've seen that there is more than one way to solve this particular problem, and - as is often the case in using Python - it is case of choosing the best tool for the job.\n",
    "\n",
    "As you work through the next experimental project, try to look for opportunities to use the techniques that you have seen in these LineFitting and PeakFitting notebooks.  You could try using appropriate functions to model and fit data from the e/m experiment and use the Gaussian peak fitting to find peaks in the X-ray spectra from the Compton experiment. \n",
    "\n",
    "You may also wish to adapt these examples to take account of the error bars in your Compton X-ray spectra."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
